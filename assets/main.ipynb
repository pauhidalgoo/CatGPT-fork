{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD THE MODEL AND START USING IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CatGPT_model import GPT, GPTConfig\n",
    "import torch\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ../models/CatGPT.pth\n"
     ]
    }
   ],
   "source": [
    "def load_model(model, model_path, device='cpu'):\n",
    "    \"\"\"\n",
    "    Load the model state dictionary from the specified path and load it into the model.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model into which the state dictionary will be loaded.\n",
    "    model_path (str): The path from where the model will be loaded.\n",
    "    device (torch.device): The device on which the model will be loaded.\n",
    "    \"\"\"\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "model = GPT(GPTConfig(vocab_size=32768))\n",
    "model = torch.compile(model)\n",
    "load_model(model, model_path=\"../models/CatGPT.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(input_text = 'La intel·ligència artificial tindrà la capactiat de', num_return_sequences = 1, max_length = 100, device='cpu'):\n",
    "\n",
    "    enc = ByteLevelBPETokenizer(\n",
    "        '../tokenizer/vocab.json',\n",
    "        '../tokenizer/merges.txt'\n",
    "    )\n",
    "\n",
    "    # Encode the input text\n",
    "    tokens = enc.encode(input_text).ids\n",
    "    tokens = torch.tensor(tokens, dtype=torch.long)  # (8,)\n",
    "\n",
    "    if len(tokens) > max_length:\n",
    "        max_length = len(tokens) + 50\n",
    "        print(f\"Max length set to {max_length} as input text is longer than the previous max length\")\n",
    "    tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)  # (B, 8)\n",
    "    x = tokens.to(device)\n",
    "\n",
    "    # Set manual seed for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # Generate sequences\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length - x.size(1)):\n",
    "            logits, _ = model(x)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, 1)\n",
    "            x = torch.cat((x, next_token), dim=1)\n",
    "\n",
    "    # Decode and print the generated sequences\n",
    "    for i in range(num_return_sequences):\n",
    "        tokens = x[i].tolist()\n",
    "        decoded = enc.decode(tokens)\n",
    "        print(f\"Sample {i+1}: {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: El arbres del bosc eren tenebrosos, un somriure es va escoltar i va ser quan va arribar el moment de conèixer tots els habitants d’aquestes muntanyes i es van acostar. Com més preocupats estaven els joves egipcis per la seva situació, més greu\n",
      "Sample 2: El arbres del bosc eren tenebrosos, un somriure es va escoltar i va ser quan al final ho vam aconseguir de nou... hem gaudit d'aquest moment i seguirem disfrutant amb les vivències cap a casa.\n",
      "Arribo a casa per fer un\n",
      "Sample 3: El arbres del bosc eren tenebrosos, un somriure es va escoltar i va ser quan va tocar el públic dempeus se'l va menjar. Havia passat més d'una hora perquè arribés l'hora, tenen dotze o setze anys —va explicar Montes\n"
     ]
    }
   ],
   "source": [
    "generate_text(input_text=\"El arbres del bosc eren tenebrosos, un somriure es va escoltar i va ser quan\", num_return_sequences=3, max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: El sol es ponia en l'horitzó de milers de colors però els pirates no podien navegar perquè no tenien por i jugaven. Així ho explica el llibre The Wall Street Journal of the TwoBooks, del professor William Shea\n",
      "Sample 2: El sol es ponia en l'horitzó de milers de colors però els pirates no podien anar ben despistats: \"Upítuma era viu\" va dir un d'ells, el cap, abraçadíssim pels dos cossos per fer\n",
      "Sample 3: El sol es ponia en l'horitzó de milers de colors però els pirates no podien desplaçar-se al Carib per a vigilar l'oest. Per això van haver de parar perquè no trobaven cap fallo! Mentre, els altres —els verd\n"
     ]
    }
   ],
   "source": [
    "generate_text(input_text=\"El sol es ponia en l'horitzó de milers de colors però els pirates no podien\", num_return_sequences=3, max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: La intel·ligència artificial tindrà la capacitat de dissenyar receptes creatives utilitzant mètodes i tècniques poc habituals. No obstant, al desconèixer quines són les més prometedores? Ara veurem si aquesta disciplina podia ser-ne una de nova i podem descobrir-ne la\n",
      "Sample 2: La intel·ligència artificial tindrà la capacitat de saber quan ho dirà la matemàtica, en aquest cas escollida pel nostre cervell. L’acusava de no tenir consciència, però el consum disparat a partir d’elles li produeix reducció de la intel·ligència\n",
      "Sample 3: La intel·ligència artificial tindrà la capacitat de desplaçar a un perifèric únicament a una velocitat. Els propers 10 anys celebrarem l'Apol·lo Boreal, tenen sentit científic i és —com ho és el que és— a partir de les\n"
     ]
    }
   ],
   "source": [
    "generate_text(input_text=\"La intel·ligència artificial tindrà la capacitat de\", num_return_sequences=3, max_length=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
